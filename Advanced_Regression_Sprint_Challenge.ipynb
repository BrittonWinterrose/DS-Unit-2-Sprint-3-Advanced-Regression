{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Unit_2_Sprint_Challenge_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "ayDccRP01GJD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Science Unit 2 Sprint Challenge 3\n",
        "\n",
        "## Logistic Regression and Beyond\n",
        "\n",
        "In this sprint challenge you will fit a logistic regression modeling the probability of an adult having an income above 50K. The dataset is available at UCI:\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/adult\n",
        "\n",
        "Your goal is to:\n",
        "\n",
        "1. Load, validate, and clean/prepare the data.\n",
        "2. Fit a logistic regression model\n",
        "3. Answer questions based on the results (as well as a few extra questions about the other modules)\n",
        "\n",
        "Don't let the perfect be the enemy of the good! Manage your time, and make sure to get to all parts. If you get stuck wrestling with the data, simplify it (if necessary, drop features or rows) so you're able to move on. If you have time at the end, you can go back and try to fix/improve.\n",
        "\n",
        "### Hints\n",
        "\n",
        "It has a variety of features - some are continuous, but many are categorical. You may find [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) (a method to one-hot encode) helpful!\n",
        "\n",
        "The features have dramatically different ranges. You may find [sklearn.preprocessing.minmax_scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.minmax_scale.html#sklearn.preprocessing.minmax_scale) helpful!"
      ]
    },
    {
      "metadata": {
        "id": "U22R1Ud51hxb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1 - Load, validate, and prepare data\n",
        "\n",
        "The data is available at: https://archive.ics.uci.edu/ml/datasets/adult\n",
        "\n",
        "Load it, name the columns, and make sure that you've loaded the data successfully. Note that missing values for categorical variables can essentially be considered another category (\"unknown\"), and may not need to be dropped.\n",
        "\n",
        "You should also prepare the data for logistic regression - one-hot encode categorical features as appropriate."
      ]
    },
    {
      "metadata": {
        "id": "C5Divbvs0VR6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SeOByIkht-NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#adult = pd.read_csv('adult.csv')\n",
        "\n",
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'educational-num','marital-status', 'occupation', 'relationship', 'race', 'gender','capital-gain', 'capital-loss', 'hours-per-week', 'native_country','income']\n",
        "\n",
        "train = pd.read_csv('adult_data.txt', sep=\",\\s\", header=None, names = column_names, engine = 'python')\n",
        "test = pd.read_csv('adult_test.txt', sep=\",\\s\", header=None, names = column_names, engine = 'python',skiprows=[0])\n",
        "test['income'].replace(regex=True,inplace=True,to_replace=r'\\.',value=r'')\n",
        "\n",
        "\n",
        "adult = pd.concat([test,train])\n",
        "adult.reset_index(inplace = True, drop = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4BjZ4ihZ2FFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "5c347d69-b594-48eb-8ec7-0f3202c18c24"
      },
      "cell_type": "code",
      "source": [
        "adult.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>educational-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>Private</td>\n",
              "      <td>226802</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>89814</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>336951</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>Private</td>\n",
              "      <td>160323</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18</td>\n",
              "      <td>?</td>\n",
              "      <td>103497</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
              "0   25    Private  226802          11th                7       Never-married   \n",
              "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
              "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
              "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
              "4   18          ?  103497  Some-college               10       Never-married   \n",
              "\n",
              "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
              "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
              "1    Farming-fishing      Husband  White    Male             0             0   \n",
              "2    Protective-serv      Husband  White    Male             0             0   \n",
              "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
              "4                  ?    Own-child  White  Female             0             0   \n",
              "\n",
              "   hours-per-week native_country income  \n",
              "0              40  United-States  <=50K  \n",
              "1              50  United-States  <=50K  \n",
              "2              40  United-States   >50K  \n",
              "3              40  United-States   >50K  \n",
              "4              30  United-States  <=50K  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "T-w6ilJR4Nue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c40f921e-a2e4-481b-ba1a-88e4cbf05858"
      },
      "cell_type": "code",
      "source": [
        "adult.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48842, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "_aDDZTQn27L5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "df49000b-1ca4-402d-8559-076956e7c966"
      },
      "cell_type": "code",
      "source": [
        "adult = adult.replace('?', np.NaN)\n",
        "\n",
        "# Which columns are missing data\n",
        "total = adult.isnull().sum().sort_values(ascending=False)\n",
        "percent = (adult.isnull().sum()/adult.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "print(missing_data.head(25))\n",
        "\n",
        "# Drop all remaining rows missing data and check shape! \n",
        "adult = adult.dropna()\n",
        "adult.head(1)\n",
        "print(adult.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 Total   Percent\n",
            "occupation        2809  0.057512\n",
            "workclass         2799  0.057307\n",
            "native_country     857  0.017546\n",
            "income               0  0.000000\n",
            "hours-per-week       0  0.000000\n",
            "capital-loss         0  0.000000\n",
            "capital-gain         0  0.000000\n",
            "gender               0  0.000000\n",
            "race                 0  0.000000\n",
            "relationship         0  0.000000\n",
            "marital-status       0  0.000000\n",
            "educational-num      0  0.000000\n",
            "education            0  0.000000\n",
            "fnlwgt               0  0.000000\n",
            "age                  0  0.000000\n",
            "(45222, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W_rJNl6n4ePC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "a4b36588-3a74-4321-bf6e-9fa7765e29fb"
      },
      "cell_type": "code",
      "source": [
        "# Make sure all NaN's were removed\n",
        "total = adult.isnull().sum().sort_values(ascending=False)\n",
        "percent = (adult.isnull().sum()/adult.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "print(missing_data.head(25))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 Total  Percent\n",
            "income               0      0.0\n",
            "native_country       0      0.0\n",
            "hours-per-week       0      0.0\n",
            "capital-loss         0      0.0\n",
            "capital-gain         0      0.0\n",
            "gender               0      0.0\n",
            "race                 0      0.0\n",
            "relationship         0      0.0\n",
            "occupation           0      0.0\n",
            "marital-status       0      0.0\n",
            "educational-num      0      0.0\n",
            "education            0      0.0\n",
            "fnlwgt               0      0.0\n",
            "workclass            0      0.0\n",
            "age                  0      0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O9qZM9uA5bic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Looks great! "
      ]
    },
    {
      "metadata": {
        "id": "qtoQBQ1w68xx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "c386b170-736c-4b63-e96a-743774bbd47d"
      },
      "cell_type": "code",
      "source": [
        "adult.native_country.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "United-States                 41292\n",
              "Mexico                          903\n",
              "Philippines                     283\n",
              "Germany                         193\n",
              "Puerto-Rico                     175\n",
              "Canada                          163\n",
              "India                           147\n",
              "El-Salvador                     147\n",
              "Cuba                            133\n",
              "England                         119\n",
              "China                           113\n",
              "Jamaica                         103\n",
              "South                           101\n",
              "Italy                           100\n",
              "Dominican-Republic               97\n",
              "Japan                            89\n",
              "Guatemala                        86\n",
              "Vietnam                          83\n",
              "Columbia                         82\n",
              "Poland                           81\n",
              "Haiti                            69\n",
              "Portugal                         62\n",
              "Iran                             56\n",
              "Taiwan                           55\n",
              "Greece                           49\n",
              "Nicaragua                        48\n",
              "Peru                             45\n",
              "Ecuador                          43\n",
              "France                           36\n",
              "Ireland                          36\n",
              "Thailand                         29\n",
              "Hong                             28\n",
              "Trinadad&Tobago                  26\n",
              "Cambodia                         26\n",
              "Yugoslavia                       23\n",
              "Outlying-US(Guam-USVI-etc)       22\n",
              "Laos                             21\n",
              "Scotland                         20\n",
              "Honduras                         19\n",
              "Hungary                          18\n",
              "Holand-Netherlands                1\n",
              "Name: native_country, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "jTp4BDVT_JAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08a74715-eb93-47ab-cc8a-2b22a7d0aa49"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Lets peep the dtypes of the remaining columns with nans. \n",
        "#columns = []\n",
        "#columns = [\"Id\"]\n",
        "#nan_columns = df.columns[df.isna().any()].tolist()\n",
        "#columns.extend(nan_columns)\n",
        "adult.dtypes\n",
        "\n",
        "counts_ = []\n",
        "object_columns = list(adult.select_dtypes(include=['object']))\n",
        "print(object_columns)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native_country', 'income']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pTdk6kCL72-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "e610d619-ec65-4c14-feed-43a116583f3b"
      },
      "cell_type": "code",
      "source": [
        "# They're either from the US or not.\n",
        "mask = adult['native_country'] == 'United-States'\n",
        "column_name = 'native_country'\n",
        "adult.loc[mask, column_name] = 1\n",
        "\n",
        "mask = adult['native_country'] != 1\n",
        "column_name = 'native_country'\n",
        "adult.loc[mask, column_name] = 0\n",
        "adult.head(4)\n",
        "\n",
        "# Lets take some of the data and see if we can do some tricky feature engineering.\n",
        "# Here I'll use Label Encoding \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "adult[object_columns] = adult[object_columns].apply(LabelEncoder().fit_transform)\n",
        "adult.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>educational-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>gender</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "      <td>226802</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>89814</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>336951</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44</td>\n",
              "      <td>2</td>\n",
              "      <td>160323</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7688</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>34</td>\n",
              "      <td>2</td>\n",
              "      <td>198693</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  workclass  fnlwgt  education  educational-num  marital-status  \\\n",
              "0   25          2  226802          1                7               4   \n",
              "1   38          2   89814         11                9               2   \n",
              "2   28          1  336951          7               12               2   \n",
              "3   44          2  160323         15               10               2   \n",
              "5   34          2  198693          0                6               4   \n",
              "\n",
              "   occupation  relationship  race  gender  capital-gain  capital-loss  \\\n",
              "0           6             3     2       1             0             0   \n",
              "1           4             0     4       1             0             0   \n",
              "2          10             0     4       1             0             0   \n",
              "3           6             0     2       1          7688             0   \n",
              "5           7             1     4       1             0             0   \n",
              "\n",
              "   hours-per-week  native_country  income  \n",
              "0              40               1       0  \n",
              "1              50               1       0  \n",
              "2              40               1       1  \n",
              "3              40               1       1  \n",
              "5              30               1       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "qIbjpx31z709",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define my X & Y\n",
        "y=adult[\"income\"]\n",
        "X=adult.drop(columns=['income'])\n",
        "\n",
        "# Going to try a standard scaling my X.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X_scaler = StandardScaler().fit(X)\n",
        "X_scaled = X_scaler.transform(X)\n",
        "\n",
        "# Here is where I split the model into test/train sets. \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PoVGMohGBQMh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Great! All the nans are removed, the data has been encoded, standardized, and split into clean test/train groups.\n"
      ]
    },
    {
      "metadata": {
        "id": "RT1LFnFO1lo6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 2 - Fit and present a Logistic Regression\n",
        "\n",
        "Your data should now be in a state to fit a logistic regression. Use scikit-learn, define your `X` (independent variable) and `y`, and fit a model.\n",
        "\n",
        "Then, present results - display coefficients in as interpretible a way as you can (hint - scaling the numeric features will help, as it will at least make coefficients more comparable to each other). If you find it helpful for interpretation, you can also generate predictions for cases (like our 5 year old rich kid on the Titanic) or make visualizations - but the goal is your exploration to be able to answer the question, not any particular plot (i.e. don't worry about polishing it).\n",
        "\n",
        "It is *optional* to use `train_test_split` or validate your model more generally - that is not the core focus for this week. So, it is suggested you focus on fitting a model first, and if you have time at the end you can do further validation."
      ]
    },
    {
      "metadata": {
        "id": "d0BuXnTsBnv9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Lets define a performance evaluation function.\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "def get_metrics(y_test, y_predicted):  \n",
        "    # true positives / (true positives+false positives)\n",
        "    precision = precision_score(y_test, y_predicted, pos_label=None,\n",
        "                                    average='weighted')             \n",
        "    # true positives / (true positives + false negatives)\n",
        "    recall = recall_score(y_test, y_predicted, pos_label=None,\n",
        "                              average='weighted')\n",
        "    \n",
        "    # harmonic mean of precision and recall\n",
        "    f1 = f1_score(y_test, y_predicted, pos_label=None, average='weighted')\n",
        "    \n",
        "    # true positives + true negatives/ total\n",
        "    accuracy = accuracy_score(y_test, y_predicted)\n",
        "    return accuracy, precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7fTRDXguD7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(max_iter=1000,\n",
        "                            n_jobs=-1, \n",
        "                            verbose=1,\n",
        "                            random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MyegIeNYBpMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "029302aa-27b4-4969-a90b-dd3596062cf7"
      },
      "cell_type": "code",
      "source": [
        "# Fit with the Original Data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# lets check the performance w/ Undersampling\n",
        "y_predicted = logreg.predict(X_test)\n",
        "accuracy, precision, recall, f1 = get_metrics(y_test, y_predicted)\n",
        "trials = []\n",
        "trials.append([\"Trial\",\"accuracy\",\"precision\",\"recall\",\"f1\"])\n",
        "trial = \"Base\"\n",
        "trials.append([trial, accuracy, precision, recall, f1])\n",
        "print(\"accuracy = %.3f, precision = %.3f, recall = %.3f, f1 = %.3f\" % (accuracy, precision, recall, f1))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibLinear]accuracy = 0.820, precision = 0.809, recall = 0.820, f1 = 0.805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9wU19SiOB7VL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.winter):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title, fontsize=30)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, fontsize=20)\n",
        "    plt.yticks(tick_marks, classes, fontsize=20)\n",
        "    \n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \n",
        "                 color=\"white\" if cm[i, j] < thresh else \"black\", fontsize=40)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    #plt.ylabel('True label', fontsize=30)\n",
        "    #plt.xlabel('Predicted label', fontsize=30)\n",
        "\n",
        "    return plt\n",
        "\n",
        "### Print a confusion matrix to inspect how well our classifier is/isn't doing.\n",
        "cm = confusion_matrix(Y_test.argmax(axis=1), prediction.argmax(axis=1), labels = [2,1,0])\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plot = plot_confusion_matrix(cm, classes=['Positive','Neutral','Negative'], normalize=False, title='Confusion matrix')\n",
        "plt.show()\n",
        "\n",
        "cm = confusion_matrix(Y_test.argmax(axis=1), prediction.argmax(axis=1), labels = [2,1,0])\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "plot = plot_confusion_matrix(cm, classes=['Positive','Neutral','Negative'], normalize=True, title='Confusion matrix')\n",
        "plt.show()\n",
        "\n",
        "print(\"Incase we've forgotten\")\n",
        "print(\"Test Data Value Counts:\\n\",test_df['classes_to_predict'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BkIa-Sa21qdC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 3 - Analysis, Interpretation, and Questions"
      ]
    },
    {
      "metadata": {
        "id": "1MZ1AvMBBJsA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Based on your above model, answer the following questions\n",
        "\n",
        "1. What are 3 features positively correlated with income above 50k?\n",
        "2. What are 3 features negatively correlated with income above 50k?\n",
        "3. Overall, how well does the model explain the data and what insights do you derive from it?\n",
        "\n",
        "*These answers count* - that is, make sure to spend some time on them, connecting to your analysis above. There is no single right answer, but as long as you support your reasoning with evidence you are on the right track.\n",
        "\n",
        "Note - scikit-learn logistic regression does *not* automatically perform a hypothesis test on coefficients. That is OK - if you scale the data they are more comparable in weight.\n"
      ]
    },
    {
      "metadata": {
        "id": "hjwWGPiqBMkR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Match the following situation descriptions with the model most appropriate to addressing them\n",
        "\n",
        "In addition to logistic regression, a number of other approaches were covered this week. Pair them with the situations they are most appropriate for, and briefly explain why.\n",
        "\n",
        "Situations:\n",
        "1. You are given data on academic performance of primary school students, and asked to fit a model to help predict \"at-risk\" students who are likely to receive the bottom tier of grades.\n",
        "2. You are studying tech companies and their patterns in releasing new products, and would like to be able to model and predict when a new product is likely to be launched.\n",
        "3. You are working on modeling expected plant size and yield with a laboratory that is able to capture fantastically detailed physical data about plants, but only of a few dozen plants at a time.\n",
        "\n",
        "Approaches:\n",
        "1. Ridge Regression\n",
        "2. Quantile Regression\n",
        "3. Survival Analysis"
      ]
    }
  ]
}